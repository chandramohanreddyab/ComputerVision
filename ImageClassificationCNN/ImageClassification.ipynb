{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the GPU for the Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #above environment variable set up cab be done another way as well\n",
    "# %env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "# %env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf v1 version\n",
    "# import tensorflow as tf\n",
    "# tf.config.gpu.set_per_process_memory_fraction(0.75)\n",
    "# tf.config.gpu.set_per_process_memory_growth(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.75\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist,cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cifar10(resize=False):\n",
    "    train = np.load('cifar10_images/cifar_train.npz')\n",
    "    x_train = train['data']\n",
    "    y_train = train['labels']\n",
    "    \n",
    "    test = np.load('cifar10_images/cifar_test.npz')\n",
    "    x_test = test['data']\n",
    "    y_test = test['labels']\n",
    "    \n",
    "    if resize:\n",
    "        x_train=resize_all(x_train, resize)\n",
    "        x_test=resize_all(x_test, resize)\n",
    "    \n",
    "    x_train=x_train.astype('float32')/255\n",
    "    x_test=x_test.astype('float32')/255\n",
    "\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(p, size):\n",
    "    return Image.fromarray(p).resize(size=(size,size))\n",
    "\n",
    "def resize_all(arr, size):\n",
    "    t = []\n",
    "    for i in range(arr.shape[0]):\n",
    "        t.append(np.array(resize(arr[i], size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "nb_classes = 10 #number classes\n",
    "\n",
    "img_rows, img_cols = 32, 32    # input image dimensions\n",
    "img_channels = 3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loading the data\n",
    "(x_mntrain, y_mntrain), (x_mntest, y_mntest) = mnist.load_data()\n",
    "(x_cfartrain, y_cfartrain), (x_cfartest, y_cfartest)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mntrain = x_mntrain.astype('float32')/255.\n",
    "x_mntest = x_mntest.astype('float32')/255.\n",
    "x_cfartrain = x_cfartrain.astype('float32')/255.\n",
    "x_cfartest = x_cfartest.astype('float32')/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_mntrain.shape)\n",
    "print(x_mntest.shape)\n",
    "print(x_cfartrain.shape)\n",
    "print(x_cfartest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mntrain=x_mntrain.reshape(-1,28,28,1)\n",
    "x_mntest=x_mntest.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_mntrain.shape)\n",
    "print(x_mntest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(10000,)\n",
      "(50000, 1)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_mntrain.shape)\n",
    "print(y_mntest.shape)\n",
    "print(y_cfartrain.shape)\n",
    "print(y_cfartest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mntrain = to_categorical(y_mntrain, nb_classes)\n",
    "y_mntest = to_categorical(y_mntest, nb_classes)\n",
    "y_cfartrain = to_categorical(y_cfartrain, nb_classes)\n",
    "y_cfartest = to_categorical(y_cfartest, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(10000, 10)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_mntrain.shape)\n",
    "print(y_mntest.shape)\n",
    "print(y_cfartrain.shape)\n",
    "print(y_cfartest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Convolution2D, Convolution3D,Dropout, BatchNormalization, Flatten,MaxPool2D\n",
    "from keras.optimizers import adam,RMSprop\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Convolution2D(32,kernel_size=(4,4),padding='same',activation='relu',input_shape=(28,28,1)))\n",
    "model.add(Convolution2D(32,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model.add(Convolution2D(64,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizor=RMSprop(learning_rate=0.001,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "ada=adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizor,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceCallback = ReduceLROnPlateau(monitor='val_acc',  patience=3, verbose=1,  factor=0.5, min_lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop=EarlyStopping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0712 - accuracy: 0.9826 - val_loss: 0.0282 - val_accuracy: 0.9910\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0770 - accuracy: 0.9819 - val_loss: 0.0419 - val_accuracy: 0.9898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238840bf088>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data without augmentaion\n",
    "model.fit(x_mntrain,y_mntrain,batch_size=30,epochs=2,validation_data=(x_mntest,y_mntest),callbacks=[earlystop,reduceCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageAug=ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=F,rotation_range=15,zoom_range=0.1,width_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageAug.fit(x_mntrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "122/122 [==============================] - 22s 182ms/step - loss: 0.1505 - accuracy: 0.9666 - val_loss: 2.2476 - val_accuracy: 0.1216\n",
      "Epoch 2/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.1320 - accuracy: 0.9709 - val_loss: 2.2847 - val_accuracy: 0.1136\n",
      "Epoch 3/30\n",
      "122/122 [==============================] - 23s 191ms/step - loss: 0.1033 - accuracy: 0.9732 - val_loss: 2.2629 - val_accuracy: 0.1136\n",
      "Epoch 4/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.1090 - accuracy: 0.9721 - val_loss: 2.2938 - val_accuracy: 0.1135\n",
      "Epoch 5/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.1072 - accuracy: 0.9771 - val_loss: 2.2448 - val_accuracy: 0.1152\n",
      "Epoch 6/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.1088 - accuracy: 0.9749 - val_loss: 2.3591 - val_accuracy: 0.1136\n",
      "Epoch 7/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.1152 - accuracy: 0.9760 - val_loss: 2.1686 - val_accuracy: 0.1368\n",
      "Epoch 8/30\n",
      "122/122 [==============================] - 23s 189ms/step - loss: 0.1040 - accuracy: 0.9754 - val_loss: 2.2482 - val_accuracy: 0.1136\n",
      "Epoch 9/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.0952 - accuracy: 0.9781 - val_loss: 2.1167 - val_accuracy: 0.1488\n",
      "Epoch 10/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.0923 - accuracy: 0.9801 - val_loss: 2.2170 - val_accuracy: 0.1142\n",
      "Epoch 11/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.0960 - accuracy: 0.9769 - val_loss: 2.3758 - val_accuracy: 0.1138\n",
      "Epoch 12/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.0965 - accuracy: 0.9784 - val_loss: 2.2651 - val_accuracy: 0.1135\n",
      "Epoch 13/30\n",
      "122/122 [==============================] - 23s 189ms/step - loss: 0.0994 - accuracy: 0.9769 - val_loss: 2.0644 - val_accuracy: 0.1646\n",
      "Epoch 14/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.0837 - accuracy: 0.9804 - val_loss: 2.7473 - val_accuracy: 0.1971\n",
      "Epoch 15/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.0915 - accuracy: 0.9806 - val_loss: 2.1632 - val_accuracy: 0.1214\n",
      "Epoch 16/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.0775 - accuracy: 0.9814 - val_loss: 2.1711 - val_accuracy: 0.1185\n",
      "Epoch 17/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.0787 - accuracy: 0.9803 - val_loss: 2.1180 - val_accuracy: 0.1399\n",
      "Epoch 18/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.0865 - accuracy: 0.9795 - val_loss: 2.4549 - val_accuracy: 0.1616\n",
      "Epoch 19/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.0865 - accuracy: 0.9808 - val_loss: 2.2761 - val_accuracy: 0.2242\n",
      "Epoch 20/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.0820 - accuracy: 0.9802 - val_loss: 2.3869 - val_accuracy: 0.1371\n",
      "Epoch 21/30\n",
      "122/122 [==============================] - 23s 189ms/step - loss: 0.0908 - accuracy: 0.9796 - val_loss: 2.1336 - val_accuracy: 0.2458\n",
      "Epoch 22/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.1046 - accuracy: 0.9787 - val_loss: 2.5737 - val_accuracy: 0.1980\n",
      "Epoch 23/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.0752 - accuracy: 0.9824 - val_loss: 1.7975 - val_accuracy: 0.3280\n",
      "Epoch 24/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.1097 - accuracy: 0.9783 - val_loss: 2.2161 - val_accuracy: 0.1392\n",
      "Epoch 25/30\n",
      "122/122 [==============================] - 23s 186ms/step - loss: 0.0833 - accuracy: 0.9795 - val_loss: 1.5758 - val_accuracy: 0.4626\n",
      "Epoch 26/30\n",
      "122/122 [==============================] - 23s 188ms/step - loss: 0.0948 - accuracy: 0.9796 - val_loss: 2.0637 - val_accuracy: 0.1794\n",
      "Epoch 27/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.0818 - accuracy: 0.9800 - val_loss: 2.1461 - val_accuracy: 0.1489\n",
      "Epoch 28/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.0770 - accuracy: 0.9807 - val_loss: 2.1079 - val_accuracy: 0.1537\n",
      "Epoch 29/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 0.0823 - accuracy: 0.9810 - val_loss: 2.0731 - val_accuracy: 0.1859\n",
      "Epoch 30/30\n",
      "122/122 [==============================] - 23s 187ms/step - loss: 1.3654 - accuracy: 0.9797 - val_loss: 1.9673 - val_accuracy: 0.1895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x238803fd048>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(imageAug.flow(x_mntest, y_mntest, batch_size=82),epochs=30,validation_data=(x_mntest,y_mntest),callbacks=[reduceCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=Sequential()\n",
    "model1.add(Convolution2D(32,kernel_size=(4,4),padding='same',activation='relu',input_shape=(32,32,3)))\n",
    "model1.add(Convolution2D(32,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Convolution2D(64,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model1.add(Convolution2D(64,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Convolution2D(128,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model1.add(Convolution2D(128,kernel_size=(4,4),padding='same',activation='relu'))\n",
    "model1.add(MaxPool2D(pool_size=(2,2)))\n",
    "model1.add(Dropout(0.25))\n",
    "\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(256,activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# compute quantities required for featurewise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied)\n",
    "datagen.fit(x_cfartrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer=ada,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1562 [==============================] - 218s 140ms/step - loss: 1.8367 - accuracy: 0.3057\n",
      "Epoch 2/5\n",
      "1563/1562 [==============================] - 222s 142ms/step - loss: 1.5380 - accuracy: 0.4334\n",
      "Epoch 3/5\n",
      "1563/1562 [==============================] - 224s 143ms/step - loss: 1.4312 - accuracy: 0.4813\n",
      "Epoch 4/5\n",
      "1563/1562 [==============================] - 224s 144ms/step - loss: 1.3681 - accuracy: 0.5086\n",
      "Epoch 5/5\n",
      "1563/1562 [==============================] - 224s 144ms/step - loss: 1.3194 - accuracy: 0.5310\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23884c01488>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits the model on batches with real-time data augmentation:\n",
    "model1.fit_generator(datagen.flow(x_cfartrain, y_cfartrain, batch_size=32),\n",
    "                    steps_per_epoch=len(x_cfartrain) / 32, epochs=5,callbacks=[reduceCallback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
